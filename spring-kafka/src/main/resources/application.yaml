spring:
  kafka:
#    bootstrap-servers:

    producer:
      key-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      compression-type: lz4

#      batch size in bytes
#      records larger than this size won't be batched
#      records are batched for each partition - so make sure that you don’t set it to a number that’s too high, otherwise you may run into high memory usages
      batch-size: 100000

      properties:
        linger.ms: 10

    consumer:
#      group-id:
#      auto-offset-reset: earliest
      key-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer

      properties:
#        cooperative re-balancing and therefore consumers can keep on consuming from the topic while the affected partition assignments are redistributed incrementally
#        useful only when small number of consumers are lost and fewer partitions need to be re-assigned
        partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor

#        unique identifier of the consumer instance to treat this instance as a static member
#        if the consumer instance re-joins before session.timeout.ms then same partitions are assigned and no re-balance occurs
#        if using kubernetes, you can map the pod metadata name to the group instance id to handle pod restarts
        group.instance.id: ${GROUP_INSTANCE_ID:1}

    # Additional properties, common to producers and consumers, used to configure the client
    properties:
      schema.registry.url: http://localhost:8081

      # derive schema subject name from record name instead of topic name
      key.subject.name.strategy: io.confluent.kafka.serializers.subject.RecordNameStrategy
      value.subject.name.strategy: io.confluent.kafka.serializers.subject.RecordNameStrategy

      specific.avro.reader: true
      use.latest.version: true

      # register schemas through schema registry plugin as part of CI/CD process
      auto.register.schemas: false

#      security:
#        protocol: SASL_SSL
#      sasl:
#        jaas:
#          config: org.apache.kafka.common.security.plain.PlainLoginModule required username='' password='';
#        mechanism: PLAIN